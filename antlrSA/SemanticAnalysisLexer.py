# Generated from /Users/marialynne/PycharmProjects/SemanticAnalysis/antlrSA/SemanticAnalysis.g4 by ANTLR 4.13.1
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
    from typing import TextIO
else:
    from typing.io import TextIO


def serializedATN():
    return [
        4,0,30,193,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,
        2,6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,
        13,7,13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,
        19,2,20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,
        26,7,26,2,27,7,27,2,28,7,28,2,29,7,29,1,0,1,0,1,1,1,1,1,2,1,2,1,
        3,1,3,1,4,1,4,1,5,1,5,1,6,1,6,1,7,1,7,1,7,1,7,1,7,1,8,1,8,1,8,1,
        9,1,9,1,10,1,10,1,11,1,11,1,12,1,12,1,13,1,13,1,13,1,14,1,14,1,14,
        1,15,1,15,1,15,1,16,1,16,1,16,1,16,1,16,1,16,1,17,1,17,1,17,1,17,
        1,18,1,18,1,18,1,18,1,18,1,18,1,19,1,19,1,19,1,19,1,20,1,20,1,20,
        1,21,1,21,1,21,1,21,1,21,1,22,1,22,1,22,1,22,1,22,1,22,1,23,1,23,
        1,23,1,23,1,23,1,24,1,24,1,24,1,24,1,24,1,24,1,24,1,25,4,25,148,
        8,25,11,25,12,25,149,1,26,4,26,153,8,26,11,26,12,26,154,1,27,4,27,
        158,8,27,11,27,12,27,159,1,27,1,27,1,27,4,27,165,8,27,11,27,12,27,
        166,1,28,1,28,5,28,171,8,28,10,28,12,28,174,9,28,1,28,1,28,1,28,
        1,28,5,28,180,8,28,10,28,12,28,183,9,28,1,28,1,28,1,29,4,29,188,
        8,29,11,29,12,29,189,1,29,1,29,0,0,30,1,1,3,2,5,3,7,4,9,5,11,6,13,
        7,15,8,17,9,19,10,21,11,23,12,25,13,27,14,29,15,31,16,33,17,35,18,
        37,19,39,20,41,21,43,22,45,23,47,24,49,25,51,26,53,27,55,28,57,29,
        59,30,1,0,4,2,0,65,90,97,122,1,0,48,57,1,0,34,34,3,0,9,10,13,13,
        32,32,199,0,1,1,0,0,0,0,3,1,0,0,0,0,5,1,0,0,0,0,7,1,0,0,0,0,9,1,
        0,0,0,0,11,1,0,0,0,0,13,1,0,0,0,0,15,1,0,0,0,0,17,1,0,0,0,0,19,1,
        0,0,0,0,21,1,0,0,0,0,23,1,0,0,0,0,25,1,0,0,0,0,27,1,0,0,0,0,29,1,
        0,0,0,0,31,1,0,0,0,0,33,1,0,0,0,0,35,1,0,0,0,0,37,1,0,0,0,0,39,1,
        0,0,0,0,41,1,0,0,0,0,43,1,0,0,0,0,45,1,0,0,0,0,47,1,0,0,0,0,49,1,
        0,0,0,0,51,1,0,0,0,0,53,1,0,0,0,0,55,1,0,0,0,0,57,1,0,0,0,0,59,1,
        0,0,0,1,61,1,0,0,0,3,63,1,0,0,0,5,65,1,0,0,0,7,67,1,0,0,0,9,69,1,
        0,0,0,11,71,1,0,0,0,13,73,1,0,0,0,15,75,1,0,0,0,17,80,1,0,0,0,19,
        83,1,0,0,0,21,85,1,0,0,0,23,87,1,0,0,0,25,89,1,0,0,0,27,91,1,0,0,
        0,29,94,1,0,0,0,31,97,1,0,0,0,33,100,1,0,0,0,35,106,1,0,0,0,37,110,
        1,0,0,0,39,116,1,0,0,0,41,120,1,0,0,0,43,123,1,0,0,0,45,128,1,0,
        0,0,47,134,1,0,0,0,49,139,1,0,0,0,51,147,1,0,0,0,53,152,1,0,0,0,
        55,157,1,0,0,0,57,168,1,0,0,0,59,187,1,0,0,0,61,62,5,59,0,0,62,2,
        1,0,0,0,63,64,5,61,0,0,64,4,1,0,0,0,65,66,5,40,0,0,66,6,1,0,0,0,
        67,68,5,41,0,0,68,8,1,0,0,0,69,70,5,123,0,0,70,10,1,0,0,0,71,72,
        5,125,0,0,72,12,1,0,0,0,73,74,5,44,0,0,74,14,1,0,0,0,75,76,5,115,
        0,0,76,77,5,113,0,0,77,78,5,114,0,0,78,79,5,116,0,0,79,16,1,0,0,
        0,80,81,5,42,0,0,81,82,5,42,0,0,82,18,1,0,0,0,83,84,5,42,0,0,84,
        20,1,0,0,0,85,86,5,47,0,0,86,22,1,0,0,0,87,88,5,43,0,0,88,24,1,0,
        0,0,89,90,5,45,0,0,90,26,1,0,0,0,91,92,5,61,0,0,92,93,5,61,0,0,93,
        28,1,0,0,0,94,95,5,62,0,0,95,96,5,61,0,0,96,30,1,0,0,0,97,98,5,60,
        0,0,98,99,5,61,0,0,99,32,1,0,0,0,100,101,5,99,0,0,101,102,5,111,
        0,0,102,103,5,110,0,0,103,104,5,115,0,0,104,105,5,116,0,0,105,34,
        1,0,0,0,106,107,5,105,0,0,107,108,5,110,0,0,108,109,5,116,0,0,109,
        36,1,0,0,0,110,111,5,102,0,0,111,112,5,108,0,0,112,113,5,111,0,0,
        113,114,5,97,0,0,114,115,5,116,0,0,115,38,1,0,0,0,116,117,5,115,
        0,0,117,118,5,116,0,0,118,119,5,114,0,0,119,40,1,0,0,0,120,121,5,
        105,0,0,121,122,5,102,0,0,122,42,1,0,0,0,123,124,5,101,0,0,124,125,
        5,108,0,0,125,126,5,115,0,0,126,127,5,101,0,0,127,44,1,0,0,0,128,
        129,5,119,0,0,129,130,5,104,0,0,130,131,5,105,0,0,131,132,5,108,
        0,0,132,133,5,101,0,0,133,46,1,0,0,0,134,135,5,102,0,0,135,136,5,
        117,0,0,136,137,5,110,0,0,137,138,5,99,0,0,138,48,1,0,0,0,139,140,
        5,114,0,0,140,141,5,101,0,0,141,142,5,116,0,0,142,143,5,117,0,0,
        143,144,5,114,0,0,144,145,5,110,0,0,145,50,1,0,0,0,146,148,7,0,0,
        0,147,146,1,0,0,0,148,149,1,0,0,0,149,147,1,0,0,0,149,150,1,0,0,
        0,150,52,1,0,0,0,151,153,7,1,0,0,152,151,1,0,0,0,153,154,1,0,0,0,
        154,152,1,0,0,0,154,155,1,0,0,0,155,54,1,0,0,0,156,158,7,1,0,0,157,
        156,1,0,0,0,158,159,1,0,0,0,159,157,1,0,0,0,159,160,1,0,0,0,160,
        161,1,0,0,0,161,162,9,0,0,0,162,164,6,27,0,0,163,165,7,1,0,0,164,
        163,1,0,0,0,165,166,1,0,0,0,166,164,1,0,0,0,166,167,1,0,0,0,167,
        56,1,0,0,0,168,172,5,34,0,0,169,171,8,2,0,0,170,169,1,0,0,0,171,
        174,1,0,0,0,172,170,1,0,0,0,172,173,1,0,0,0,173,181,1,0,0,0,174,
        172,1,0,0,0,175,176,5,34,0,0,176,177,5,34,0,0,177,178,1,0,0,0,178,
        180,8,2,0,0,179,175,1,0,0,0,180,183,1,0,0,0,181,179,1,0,0,0,181,
        182,1,0,0,0,182,184,1,0,0,0,183,181,1,0,0,0,184,185,5,34,0,0,185,
        58,1,0,0,0,186,188,7,3,0,0,187,186,1,0,0,0,188,189,1,0,0,0,189,187,
        1,0,0,0,189,190,1,0,0,0,190,191,1,0,0,0,191,192,6,29,1,0,192,60,
        1,0,0,0,8,0,149,154,159,166,172,181,189,2,1,27,0,6,0,0
    ]

class SemanticAnalysisLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    T__0 = 1
    T__1 = 2
    T__2 = 3
    T__3 = 4
    T__4 = 5
    T__5 = 6
    T__6 = 7
    T__7 = 8
    T__8 = 9
    T__9 = 10
    T__10 = 11
    T__11 = 12
    T__12 = 13
    T__13 = 14
    T__14 = 15
    T__15 = 16
    CONST = 17
    INT = 18
    FLOAT = 19
    STRING = 20
    IF = 21
    ELSE = 22
    WHILE = 23
    FUNC = 24
    RETURN = 25
    ID = 26
    INTEGER = 27
    DEC = 28
    STR = 29
    WS = 30

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "';'", "'='", "'('", "')'", "'{'", "'}'", "','", "'sqrt'", "'**'", 
            "'*'", "'/'", "'+'", "'-'", "'=='", "'>='", "'<='", "'const'", 
            "'int'", "'float'", "'str'", "'if'", "'else'", "'while'", "'func'", 
            "'return'" ]

    symbolicNames = [ "<INVALID>",
            "CONST", "INT", "FLOAT", "STRING", "IF", "ELSE", "WHILE", "FUNC", 
            "RETURN", "ID", "INTEGER", "DEC", "STR", "WS" ]

    ruleNames = [ "T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", 
                  "T__7", "T__8", "T__9", "T__10", "T__11", "T__12", "T__13", 
                  "T__14", "T__15", "CONST", "INT", "FLOAT", "STRING", "IF", 
                  "ELSE", "WHILE", "FUNC", "RETURN", "ID", "INTEGER", "DEC", 
                  "STR", "WS" ]

    grammarFileName = "SemanticAnalysis.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.13.1")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


    def action(self, localctx:RuleContext, ruleIndex:int, actionIndex:int):
        if self._actions is None:
            actions = dict()
            actions[27] = self.DEC_action 
            self._actions = actions
        action = self._actions.get(ruleIndex, None)
        if action is not None:
            action(localctx, actionIndex)
        else:
            raise Exception("No registered action for:" + str(ruleIndex))


    def DEC_action(self, localctx:RuleContext , actionIndex:int):
        if actionIndex == 0:
            1
     


